# [API Reference](../API.md) - Models

| Model Type                                                        | Description                                     | Count |
|-------------------------------------------------------------------|-------------------------------------------------|-------|
| [Deep Reinforcement Learning](#deep-reinforcement-learning)       | State-Action Optimization Using Neural Networks | 26    |
| [Generative](#generative)                                         | Feature To Novel Value                          | 4     |
| Total                                                             |                                                 | 30    |

### Legend

| Icon | Name                        | Description                                            |
|------|-----------------------------|--------------------------------------------------------|
| â—   | Implementation Issue       | The model may have some implementation problems.        |
| ğŸ”°   | Beginner Algorithm         | Commonly taught to beginners.                           |
| ğŸ’¾   | Data Efficient             | Require few data to train the model.                    |
| âš¡   | Computationally Efficient  | Require few computational resources to train the model. |
| ğŸ›¡ï¸   | Noise Resistant            | Can handle randomness / unclean data.                   |
| ğŸŸ¢   | Online                     | Can adapt real-time.                                    |
| ğŸŸ¡   | Session-Adaptive / Offline | Can be retrained each session.                          |
| âš ï¸   | Assumption-Heavy           | Have restrictive rules on using the model.              |
| âš™ï¸   | Configuration-Heavy        | Requires a lot of manual configuration to use.          |

## Deep Reinforcement Learning

## Deep Reinforcement Learning

> â—Implementation Issue ğŸ”° Beginner Algorithm ğŸ’¾ Data Efficient âš¡ Computationally Efficient ğŸ›¡ï¸ Noise Resistant ğŸŸ¢ Onlineâ€ƒğŸŸ¡ Session-Adaptive / Offlineâ€ƒâš ï¸ Assumption-Heavy âš™ï¸ Configuration-Heavy

| Model                                                                                                          | Alternate Names               | Properties  | Use Cases                                                                 |
|----------------------------------------------------------------------------------------------------------------|-------------------------------|-------------|---------------------------------------------------------------------------|
| [DeepQLearning](Models/DeepQLearning.md)                                                                       | Deep Q Network                | ğŸ’¾ ğŸŸ¢      | Best Self-Learning Player AIs, Best Recommendation Systems                |
| [DeepNStepQLearning](Models/DeepNStepQLearning.md)                                                             | Deep N-Step Q Network          | ğŸ’¾ ğŸŸ¢      | Best Self-Learning Player AIs, Best Recommendation Systems                |
| [DeepDoubleQLearningV1](Models/DeepDoubleQLearningV1.md)                                                       | Double Deep Q Network (2010)  | ğŸ’¾ ğŸ›¡ï¸ ğŸŸ¢   | Stable Best Self-Learning Player AIs, Best Recommendation Systems         |
| [DeepDoubleQLearningV2](Models/DeepDoubleQLearningV2.md)                                                       | Double Deep Q Network (2015)  | ğŸ’¾ ğŸ›¡ï¸ ğŸŸ¢   | Stable Best Self-Learning Player AIs, Best Recommendation Systems         |
| [DeepClippedDoubleQLearning](Models/DeepClippedDoubleQLearning.md)                                             | Clipped Deep Double Q Network | ğŸ’¾ ğŸ›¡ï¸ ğŸŸ¢   | Stable Best Self-Learning Player AIs, Best Recommendation Systems         |
| [DeepStateActionRewardStateAction](Models/DeepStateActionRewardStateAction.md)                                 | Deep SARSA                    | ğŸŸ¢          | Safe Self-Learning Player AIs, Safe Recommendation Systems                |
| [DeepNStepStateActionRewardStateAction](Models/DeepNStepStateActionRewardStateAction.md)                       | Deep N-Step SARSA             | ğŸŸ¢          | Safe Self-Learning Player AIs, Safe Recommendation Systems                |
| [DeepDoubleStateActionRewardStateActionV1](Models/DeepDoubleStateActionRewardStateActionV1.md)                 | Double Deep SARSA             | ğŸ›¡ï¸ ğŸŸ¢      | Stable Safe Self-Learning Player AIs, Safe Recommendation Systems         |
| [DeepDoubleStateActionRewardStateActionV2](Models/DeepDoubleStateActionRewardStateActionV2.md)                 | Double Deep SARSA             | ğŸ›¡ï¸ ğŸŸ¢      | Stable Safe Self-Learning Player AIs, Safe Recommendation Systems         |
| [DeepExpectedStateActionRewardStateAction](Models/DeepExpectedStateActionRewardStateAction.md)                 | Deep Expected SARSA           | ğŸŸ¢         | Balanced Self-Learning Player AIs, Balanced Recommendation Systems        |
| [DeepNStepExpectedStateActionRewardStateAction](Models/DeepExpectedStateActionRewardStateAction.md)            | Deep N-Step Expected SARSA    | ğŸŸ¢         | Balanced Self-Learning Player AIs, Balanced Recommendation Systems        |
| [DeepDoubleExpectedStateActionRewardStateActionV1](Models/DeepDoubleExpectedStateActionRewardStateActionV1.md) | Double Deep Expected SARSA    | ğŸ›¡ï¸ ğŸŸ¢      | Stable Balanced Self-Learning Player AIs, Balanced Recommendation Systems |
| [DeepDoubleExpectedStateActionRewardStateActionV2](Models/DeepDoubleExpectedStateActionRewardStateActionV2.md) | Double Deep Expected SARSA    | ğŸ›¡ï¸ ğŸŸ¢      | Stable Balanced Self-Learning Player AIs, Balanced Recommendation Systems |
| [MonteCarloControl](Models/MonteCarloControl.md)                                                               | None                          | â— ğŸŸ¢      | Online Self-Learning Player AIs                                           |
| [OffPolicyMonteCarloControl](Models/OffPolicyMonteCarloControl.md)                                             | None                          | ğŸŸ¢         | Offline Self-Learning Player AIs                                          |
| [DeepTemporalDifference](Models/DeepTemporalDifference.md)                                                     | TD                            | ğŸŸ¢         | Priority Systems                                                          |
| [REINFORCE](Models/REINFORCE.md)                                                                               | None                          | ğŸŸ¢         | Reward-Based Self-Learning Player AIs                          |
| [VanillaPolicyGradient](Models/VanillaPolicyGradient.md)                                                       | VPG                           | â— ğŸŸ¢      | Baseline-Based Self-Learning Player AIs                                   |
| [ActorCritic](Models/ActorCritic.md)                                                                           | AC                            | ğŸŸ¢         | Critic-Based Self-Learning Player AIs                                     |
| [AdvantageActorCritic](Models/AdvantageActorCritic.md)                                                         | A2C                           | ğŸŸ¢         | Advantage-Based Self-Learning Player AIs                                  |
| [TemporalDifferenceActorCritic](Models/TemporalDifferenceActorCritic.md)                                       | TD-AC                         | ğŸŸ¢         | Bootsrapped Online Self-Learning Player AIs                               |
| [ProximalPolicyOptimization](Models/ProximalPolicyOptimization.md)                                             | PPO                           | ğŸŸ¢         | Industry-Grade And Research-Grade Self-Learning Player And Vehicle AIs    |
| [ProximalPolicyOptimizationClip](Models/ProximalPolicyOptimizationClip.md)                                     | PPO-Clip                      | ğŸŸ¢         | Industry-Grade And Research-Grade Self-Learning Player And Vehicle AIs    |
| [SoftActorCritic](Models/SoftActorCritic.md)                                                                   | SAC                           | ğŸ’¾ ğŸ›¡ï¸ ğŸŸ¢  | Self-Learning Vehicle AIs                                                 |
| [DeepDeterministicPolicyGradient](Models/DeepDeterministicPolicyGradient.md)                                   | DDPG                          | ğŸŸ¢         | Self-Learning Vehicle AIs                                                 |
| [TwinDelayedDeepDeterministicPolicyGradient](Models/TwinDelayedDeepDeterministicPolicyGradient.md)             | TD3                           | ğŸŸ¢ ğŸ›¡ï¸      | Self-Learning Vehicle AIs                                                 |

## Generative

> â—Implementation Issue ğŸ”° Beginner Algorithm ğŸ’¾ Data Efficient âš¡ Computationally Efficient ğŸ›¡ï¸ Noise Resistant ğŸŸ¢ Onlineâ€ƒğŸŸ¡ Session-Adaptive / Offlineâ€ƒâš ï¸ Assumption-Heavy âš™ï¸ Configuration-Heavy

| Model                                                                                                              | Alternate Names | Properties | Use Cases                                 |
|--------------------------------------------------------------------------------------------------------------------|-----------------|------------| ------------------------------------------|
| [Diffusion](Models/Diffusion.md)                                                                                   | None            | ğŸŸ¢ ğŸŸ¡     | Building And Image Generation             |
| [GenerativeAdversarialNetwork](Models/GenerativeAdversarialNetwork.md)                                             | GAN             | ğŸŸ¢ ğŸŸ¡     | Enemy Data Generation                     |
| [ConditionalGenerativeAdversarialNetwork](Models/ConditionalGenerativeAdversarialNetwork.md)                       | CGAN            | ğŸŸ¢ ğŸŸ¡     | Conditional Enemy Data Generation         |
| [WassersteinGenerativeAdversarialNetwork](Models/WassersteinGenerativeAdversarialNetwork.md)                       | WGAN            | ğŸŸ¢ ğŸŸ¡     | Stable Enemy Data Generation              |
| [ConditionalWassersteinGenerativeAdversarialNetwork](Models/ConditionalWassersteinGenerativeAdversarialNetwork.md) | CWGAN           | ğŸŸ¢ ğŸŸ¡     | Stable Conditional Enemy Data Generation  |

## Others

> â—Implementation Issue ğŸ”° Beginner Algorithm ğŸ’¾ Data Efficient âš¡ Computationally Efficient ğŸ›¡ï¸ Noise Resistant ğŸŸ¢ Onlineâ€ƒğŸŸ¡ Session-Adaptive / Offlineâ€ƒâš ï¸ Assumption-Heavy âš™ï¸ Configuration-Heavy

| Model                                                                  | Alternate Names |  Properties | Use Cases                             |
|------------------------------------------------------------------------|-----------------|-------------|---------------------------------------|
| [RandomNetworkDistillation](Models/RandomNetworkDistillation.md)       | RND             | ğŸŸ¢ ğŸŸ¡      | Intrinsic Reward Generation           |

## BaseModels

[BaseModel](Models/BaseModel.md)

[ReinforcementLearningBaseModel](Models/ReinforcementLearningBaseModel.md)

[ReinforcementLearningActorCriticBaseModel](Models/ReinforcementLearningActorCriticBaseModel.md)
